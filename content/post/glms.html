---
title: "GLM links and distributions"
date: 2020-09-09
author: Nick Griffiths
categories: Statistics
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>Generalized Linear Models allows transformations of the predictor terms using a link function <span class="math inline">\(\eta\)</span>:</p>
<p><span class="math display">\[\eta(y) = \beta_0 + \beta_1 x_1 + ... + \beta_n x_n\]</span></p>
<p>When we use maximum likelihood, <span class="math inline">\(y = \eta^{-1}(\beta_0 + \beta_1 x_1 ...)\)</span> is part of what is used to calculate the likelihood: <span class="math inline">\(\ell = P(y_{obs} | y)\)</span>. The other piece is the assumed distribution of <span class="math inline">\(y_{obs}\)</span>.</p>
<div id="the-distribution" class="section level2">
<h2>The distribution</h2>
<p>When analyzing binary data with a logit link, <span class="math inline">\(y_{obs}\)</span> is logically given a bernoulli distribution. We assign likelihood <span class="math inline">\(y\)</span> to all <span class="math inline">\(y_{obs} = 1\)</span> and <span class="math inline">\(1 - y\)</span> to all <span class="math inline">\(y_{obs} = 0\)</span> (<span class="math inline">\(y\)</span> is a probability, not odds or logit).</p>
<p>When using log-binomial regression, implementations aren’t as robust and the models often fail to converge. So with a log link people often use a poisson distribution. However, the variance of poisson is equal to <span class="math inline">\(y = \eta^{-1}(x_1, x_2, ...)\)</span>, and it overestimates the variance of a bernoulli outcome, which is only <span class="math inline">\(p(1-p) = y(1 - y)\)</span>. So the poisson’s CIs are too wide and the usual solution is to use robust variance estimators instead.</p>
</div>
<div id="link-functions" class="section level2">
<h2>Link functions</h2>
<p>Link functions have two main effects:</p>
<p>Their domain and range can differ. In binary data, the logit link <span class="math inline">\(\eta(y) = log(\frac{y}{1-y})\)</span> is great because it is a function <span class="math inline">\((0,1) \to \mathbb{R}\)</span>. This means all values of the predictor terms are always one-to-one with a valid probability. (Note that the log link is <span class="math inline">\((0,1) \to (-\infty,0)\)</span> which means that invalid probability predictions are still possible with a log link and arbitrary predictors).</p>
<p>Changes in predictors result in different changes in the outcome. With an identity link, predictors have an additive effect on the outcome. With a log or logit link, predictors have a multiplicative impact on the outcome.</p>
</div>
<div id="offsets" class="section level2">
<h2>Offsets</h2>
<p>When modeling count data, an offset term is used to correct for processes with different rates. For example, we can model the number of hypoglycemic events over time like so:</p>
<p><span class="math display">\[y = \lambda t\]</span></p>
<p><span class="math display">\[log(y) = \beta_0 + \beta_1 x_1 + ... + log(t)\]</span></p>
<p>Where <span class="math inline">\(y\)</span> is the number of events and <span class="math inline">\(t\)</span> is the time the person was followed. The outcome <span class="math inline">\(y\)</span> is a count variable which can be modeled with a poisson distribution. With the log link, predicted counts are always positive.</p>
</div>
<div id="interpretating-parameters" class="section level2">
<h2>Interpretating parameters</h2>
<p>If the outcome is binary, then each <span class="math inline">\(y_{obs}\)</span> is <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span> and <span class="math inline">\(\mathbb{E}(y_{obs})\)</span> is a probability. When interpreting the coefficients, an identity link would correspond with a linear relationship between the probability and the predictor (though it is hardly used). A log link corresponds with a log relative risk: <span class="math inline">\(\beta = log(y_1) - log(y_2) = \log(y_1 / y_2)\)</span>. A logit link corresponds with a log odds ratio.</p>
<p>With a time offset, <span class="math inline">\(\beta_0 + \beta_1 x_1 + ...\)</span> equals <span class="math inline">\(log(y/t)\)</span>, which is the event <em>rate</em>. So the coefficients in poisson regression are log rate ratios, not risk ratios.</p>
</div>
