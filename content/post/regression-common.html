---
title: "Regression cheat sheet: general topics"
date: 2020-04-27
author: Nick Griffiths
categories: Statistics
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="predictors" class="section level2">
<h2>Designing predictor terms</h2>
<p>In the linear regression model <span class="math inline">\(Y = \beta_0 + \beta_1 X_1 + ...\)</span>, coefficients <span class="math inline">\(\beta\)</span> relate each <span class="math inline">\(X_i\)</span> to <span class="math inline">\(Y\)</span>.</p>
<p>Predictor variables <span class="math inline">\(X_i\)</span> can take any form:</p>
<ul>
<li>Continuous: <span class="math inline">\(\beta\)</span> captures change in <span class="math inline">\(Y\)</span> per unit change in <span class="math inline">\(X\)</span></li>
<li>Indicator (<span class="math inline">\(X \in \{0, 1\}\)</span>): <span class="math inline">\(\beta\)</span> is the difference between categories
<ul>
<li>Make dummy variables for categorical predictors</li>
</ul></li>
<li>Interaction (<span class="math inline">\(X_1 X_2)\)</span>: captures modification of the effect of one variable by another</li>
<li>Polynomial (<span class="math inline">\(X^a\)</span>): allow for nonlinear effects
<ul>
<li>Natural cubic splines are a common flexible choice</li>
</ul></li>
</ul>
</div>
<div id="fit" class="section level2">
<h2>Regression goodness of fit</h2>
<p>Ways to test goodness of fit:</p>
<ul>
<li>Tests of the global null hypothesis, which is that the intercept-only model fits as well as the full model
<ul>
<li>The intercept-only model is nested within the full model, so likelihood ratio test can be used</li>
<li>Wald and Score test are also available but are less reliable</li>
</ul></li>
<li>Information criteria
<ul>
<li>These balance underfitting against overfitting – additional parameters will only reduce information criteria when they offset complexity with better fit</li>
</ul></li>
<li>Explained variance</li>
</ul>
</div>
<div id="diagnostics" class="section level2">
<h2>Regression diagnostics</h2>
<p>Detecting outliers using residuals:</p>
<ul>
<li>Pearson residuals
<ul>
<li>Sum of squared pearson residuals is the <span class="math inline">\(\chi^2\)</span> statistic</li>
</ul></li>
<li>Deviance residuals
<ul>
<li>Sum of squared deviance residuals is the deviance of the model</li>
</ul></li>
</ul>
<p>Detecting influential points:</p>
<ul>
<li>Leverage
<ul>
<li>Distance of independent variable values from those of other observations</li>
</ul></li>
<li>Dfbeta
<ul>
<li>Identify influential observations on estimates of each parameter</li>
</ul></li>
<li>Cook’s distance
<ul>
<li>Influence of an observation overall</li>
</ul></li>
</ul>
</div>
<div id="gee" class="section level2">
<h2>GEE</h2>
<p>GEE allows unbiased estimation when there are clusters of correlated observations. It involves specifying a covariance matrix for the set of repeated outcome observations <span class="math inline">\(y_i\)</span>.</p>
<p>Normally we assume independence. This is the independence matrix with three measurements per subject/cluster:</p>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1
\end{bmatrix}
\]</span></p>
<p>But with GEE we specify any covariance structure for the outcomes. Using robust standard errors, the model will result in unbiased estimates even if the covariance structure is wrong. GEE is also an option to account for overdispersion in Poisson regression.</p>
</div>
<div id="interpretation" class="section level2">
<h2>Parameter interpretation</h2>
<p>One way to interpret parameter estimates is to check the standardized beta, which normalizes estimates by the standard error.</p>
<p>Profile likelihood confidence intervals can be more accurate than Wald confidence intervals with small sample sizes.</p>
</div>
<div id="mult-imputation" class="section level2">
<h2>Multiple imputation</h2>
<p>For this to work, data must either be MCAR, or it must be MAR with correct predictors available to use for imputation.</p>
<p>Procedure:</p>
<ol style="list-style-type: decimal">
<li>Fit a regression with missing values as the outcome</li>
<li>Impute predicted values using <span class="math inline">\(x = x_{pred} + \epsilon\)</span>, where <span class="math inline">\(\epsilon\)</span> is a random normal term with the same variance as the regression residuals</li>
<li>Make multiple copies of imputed datasets (&gt;5)</li>
<li>Fit the model for each dataset and estimate parameters by pooling results</li>
</ol>
<p>Note: If multiple variables have missing values, we will have a multivariate normal distribution that can be sampled using MCMC. If the pattern of missingness is monotone (as for unfinished surveys) the values can be imputed sequentially instead.</p>
</div>
