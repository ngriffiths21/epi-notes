---
title: "Survival Analysis"
date: 2020-09-13
author: Nick Griffiths
categories: Statistics
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>Survival analysis is about outcomes defined in terms of time before some event. <em>Survival time</em> is the time from a subjectâ€™s entry into the study until the event.</p>
<p>The <em>cumulative distribution function</em> <span class="math inline">\(F(t)\)</span> for survival time is the probability that the event already occurred, and equivalently, the proportion of people who had the event. It is the same as cumulative risk. The <em>survival function</em>, <span class="math inline">\(S(t) = 1 - F(t)\)</span> is the probability of surviving at least as long as a given time, or the proportion still surviving at a given time.</p>
<p>From these two functions we get three others. The <em>probability density function</em> of survival time is the derivative of the CDF, <span class="math inline">\(f(t) = \frac{d}{dt} F(t)\)</span>.</p>
<p>The <em>hazard function</em> <span class="math inline">\(h(t)\)</span> is the ratio of the PDF to the survival function, <span class="math inline">\(h(t) = \frac{f(t)}{S(t)}\)</span>. It is the derivative of the CDF for the subset that survived to that point (called the <em>risk set</em>). It is the probability density conditional on survival.</p>
<p>The hazard function is important because it is equal to the instantaneous event rate per person at risk. If there is a constant event rate, the hazard will remain constant, but the PDF will not, because the PDF corresponds to the instantaneous risk in the original cohort. It goes down as the number of people still at risk decreases.</p>
<p>The <em>cumulative hazard function</em> <span class="math inline">\(H(t)\)</span> is the integral of the hazard:</p>
<p><span class="math display">\[\int_0^t h(t) dt\]</span></p>
<p>The cumulative hazard can be interpreted as the total amount of risk over the period, or the total amount of events per one at-risk person expected over that period of time.</p>
<div id="modeling" class="section level2">
<h2>Modeling</h2>
<p>Survival analysis often uses either accelerated failure time or Cox proportional hazard models.</p>
<div id="aft-models" class="section level3">
<h3>AFT models</h3>
<p>In accelerated failure time, survival time (time to event) is modeled:</p>
<p><span class="math display">\[log(T) = \beta_0 + \beta_1 x_1\]</span></p>
<p>The time <span class="math inline">\(T\)</span> is often modeled with an exponential, weibull, log-normal, or generalized gamma distribution. Exponential has a constant hazard function <span class="math inline">\(\lambda = \frac{1}{\mathbb{E}(T)}\)</span>, so it has no additional parameters.</p>
<p>The Weibull allows the hazard can change over time. The Weibull distribution for T is equivalent to an exponential distribution for <span class="math inline">\(T^p\)</span>, <span class="math inline">\(T^p \sim E(\lambda)\)</span>. The parameter <span class="math inline">\(p\)</span> is estimated in addition to the regression coefficients, since the regression coefficients only determine <span class="math inline">\(\mathbb{E}(T)\)</span>. The hazard for this distribution is <span class="math inline">\(h(t) = \lambda^p p t^{p-1}\)</span>.</p>
<p>The log-normal distribution for <span class="math inline">\(T\)</span> is equivalent to the distribution when <span class="math inline">\(log(T)\)</span> has a normal distribution. So it is the same as using linear regression with outcome <span class="math inline">\(y = log(T)\)</span>. It requires estimating a scale parameter.</p>
<p>The generalized gamma distribution has the Weibull and exponential nested within it, as well as the log-normal distribution. It involves a scale and a shape parameter in addition to the regression coefficients.</p>
</div>
<div id="proportional-hazards" class="section level3">
<h3>Proportional hazards</h3>
<p>Cox models are specified like this:</p>
<p><span class="math display">\[h(t) = \lambda_0 exp(\beta_1 x_1 + \beta_2 x_2 + ...)\]</span></p>
<p>The Cox proportional hazards model is estimated in terms of the <em>partial likelihood</em>.</p>
<p>At each event time, the full likelihood is the probability of someone failing times the probability of it being that particular subject. In AFT, the first part is derived from the assumed distribution of the failure times. But in Cox modeling we throw away the first part and just model the second, which leaves the baseline hazard rate, <span class="math inline">\(\lambda_0\)</span>, completely unspecified. This makes it a semi-parametric model. But it assumes that the hazard of each individual is a constant proportion of all the other hazards.</p>
<p>The partial likelihood at each event time is the hazard for the individual who failed divided by the total hazard:</p>
<p><span class="math display">\[\ell_t = \frac{h_i}{\sum_{j = 1}^n h_j}\]</span></p>
<p>where <span class="math inline">\(n\)</span> is the number of subjects left in the risk set. Note that in each <span class="math inline">\(h\)</span> term the baseline hazard <span class="math inline">\(\lambda_0\)</span> cancels out. The partial likelihood is the product of the likelihood at each time, and this is what the Cox model maximizes.</p>
</div>
</div>
